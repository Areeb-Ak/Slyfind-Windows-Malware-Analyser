import subprocess
import time
import os
import pandas as pd
import pickle  # Assuming your model is saved using joblib
import warnings
import sys
# Set warnings to be ignored (filter out all warnings)
warnings.filterwarnings("ignore")


def process_flow_csv(flow_csv_path):
    # Read the CSV file into a DataFrame
    df = pd.read_csv(flow_csv_path)

    # Apply desired column drops
    df = df.drop(columns=['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Protocol', 'Timestamp'])
    df = df.drop(columns=['Dst Port', 'Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg',
                          'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg','Label','Flow Byts/s','Flow Pkts/s'])
    cols_to_replace = ['FlowDuration', 'TotalFwdPackets', 'TotalBackwardPackets',
                   'TotalLengthofFwdPackets', 'TotalLengthofBwdPackets',
                   'FwdPacketLengthMax', 'FwdPacketLengthMin', 'FwdPacketLengthMean',
                   'FwdPacketLengthStd', 'BwdPacketLengthMax', 'BwdPacketLengthMin',
                   'BwdPacketLengthMean', 'BwdPacketLengthStd', 'FlowIATMean',
                   'FlowIATStd', 'FlowIATMax', 'FlowIATMin', 'FwdIATTotal', 'FwdIATMean',
                   'FwdIATStd', 'FwdIATMax', 'FwdIATMin', 'BwdIATTotal', 'BwdIATMean',
                   'BwdIATStd', 'BwdIATMax', 'BwdIATMin', 'FwdPSHFlags', 'FwdURGFlags',
                   'FwdHeaderLength', 'BwdHeaderLength', 'FwdPackets/s', 'BwdPackets/s',
                   'MinPacketLength', 'MaxPacketLength', 'PacketLengthMean',
                   'PacketLengthStd', 'PacketLengthVariance', 'FINFlagCount',
                   'SYNFlagCount', 'RSTFlagCount', 'PSHFlagCount', 'ACKFlagCount',
                   'URGFlagCount', 'CWEFlagCount', 'ECEFlagCount', 'Down/UpRatio',
                   'AveragePacketSize', 'AvgFwdSegmentSize', 'AvgBwdSegmentSize',
                   'SubflowFwdPackets', 'SubflowFwdBytes', 'SubflowBwdPackets',
                   'SubflowBwdBytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward',
                   'act_data_pkt_fwd', 'min_seg_size_forward', 'ActiveMean', 'ActiveStd',
                   'ActiveMax', 'ActiveMin', 'IdleMean', 'IdleStd', 'IdleMax', 'IdleMin']

    # Replace the columns in the DataFrame
    df.columns = cols_to_replace

    return df

def save_predictions(predictions, output_path):
    # Convert predictions to a DataFrame
    predictions_df = pd.DataFrame({'Label': predictions})

    # Save predictions to a CSV file
    predictions_df.to_csv(output_path, index=False)
    print("Predictions saved to:", output_path)

def load_pickle_model(model_filename):
    with open(model_filename, 'rb') as file:
        model = pickle.load(file)
    return model

def decision(preds):
    if preds.count("BENIGN") == 8:
        return "BENIGN"
    else:
        for i in preds:
            if i != "BENIGN":
                return i

def main():
    capture_duration = sys.argv[3]  # 20 seconds
    capture_output_file = sys.argv[1]
    output_directory = sys.argv[2]
    model_path = f"{sys.argv[4]}/sherlock_ids_hyp1.pkl"
    scaled_path = f"{sys.argv[4]}/dr_watson_scale.pkl"
    model_filenames = [
        f"{sys.argv[4]}/ids_bot.pkl",
        f"{sys.argv[4]}/ids_DDoS.pkl",
        f"{sys.argv[4]}/ids_DoS.pkl",
        f"{sys.argv[4]}/ids_heart.pkl",
        f"{sys.argv[4]}/ids_infiltration.pkl",
        f"{sys.argv[4]}/ids_patrator.pkl",
        f"{sys.argv[4]}/ids_port_scan.pkl",
        f"{sys.argv[4]}/ids_web_attack.pkl"
    ]

    try:
        # Check if the capture file exists
        if os.path.exists(capture_output_file):

            a = (capture_output_file.split("\\")[-1]).split(".pcap")[0]
            # Process the flow CSV file
            flow_csv_path = f"{output_directory}\\{a}.pcap_Flow.csv"
            df = process_flow_csv(flow_csv_path)

            # Load the pre-trained model
            loaded_models = []
            for filename in model_filenames:
                model = load_pickle_model(filename)
                loaded_models.append(model)

            predictions = [model.predict(df) for model in loaded_models]


            flows_pred = []

            for i in range(0, len(predictions[0])):
                flow_row = [predictions[j][i] for j in range(len(predictions))]
                flows_pred.append(decision(flow_row))

            # Save predictions
            predictions_output_path = f"{output_directory}\\predictions.csv"
            save_predictions(flows_pred, predictions_output_path)
        else:
            print("Capture file does not exist.")

    except Exception as e:
        print("An error occurred:", e)


if __name__ == "__main__":
    main()
